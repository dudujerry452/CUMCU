# 数学建模反问题

目录

基本问题

反问题

结构化参数化+识别



## 背景问题 

- 分析
- 设计
- 预报
- 决策
- 控制
- 优化
- 规划
- 管理

## 基本问题

直接简单的确定量与量之间的关系, 即求映射/函数

## 结构化参数化

1. 选定函数结构, 实现待求函数的结构化和参数化, 将求函数问题转换为求参数的问题
2. 识别待定的参数. 有两种: 
   - 方程 (参数需要满足的方程, 如拉格朗日插值)
   - 优化 (参数需追求的目标, 如最佳逼近)

经典方法: 插值, 拟合: 结构化参数化+识别求函数的方法( 正交函数组:  结构化, 正交函数族参数如$\varphi(x) = \sum a_il_i(x)$ 中的参数$a_i$为参数)

### 例子: 2015A 太阳影子定位

1. 找到函数
   $$
   l = l(L,D,t,\phi,\delta, \alpha, \theta, \omega)
   $$
   其中$\phi$为纬度, $\delta$为赤纬角, $\alpha$为时角, $\theta$为太阳高度角, n为折射率, $\omega$为影子方位角. 

   

   其中有四个独立变量$L,D,t,\phi$是独立变量, 知道了之后就可以求第一问, 这里的信息查函数就可以知道. 

2. 

### 例子: 炉温曲线

1. 找到函数, 芯片中心点在炉子之间移动时的温度曲线. 

   更复杂. 但查文献可推进进度. 



## 反问题

正问题: 由因及果, 问题是==适定的==. 

反问题: 正问题存在未知因素, 由表象追根溯源, 由表及里确定系统未知因素, 与正问题演化方向相反, 如参数识别和确定污染源.

适定性: 

- 解是存在的
- 解是唯一的
- 解相对于一致的条件是有连续依赖关系的, 即解相对于条件是连续的, 不会因为小的扰动造成巨大影响. 

#### 例子

$R = 2\sqrt{h(D-h)}$

正问题: 已知D,h求R; 反问题: 已知R, D求h(需解一个一元二次方程)

### 反问题的基础是正问题

解决反问题的基础是分析清楚研究对象服从的规律, 即弄清楚正问题. 

原象: 空间, 时间, 系统的源,系统的初始状态, 影响系统的其他参数 

-(映射)> 象: 系统状态 

正问题: 已知原象, 求到象的映射, 通常是适定的; 

反问题: 若有原象未知, 部分象已知, 求未知原象, 通常是不适定的(一般是不唯一)  

> [!NOTE]
>
> 例如, 炉温曲线中热交换系数(原象)未知

### 反问题建模方法逻辑

1. 首先建立系统中所有相关量应该满足的关联关系, 记为模型I

   全部原象为$(\alpha, \beta)$, 已知的是$\alpha$, 未知的为$\beta$, 象为u, 则
   $$
   模型I: u = u(\alpha, \beta)
   $$

   > [!NOTE]
   >
   > 例如, 炉温曲线中两侧给定温度下, 热传导到中心一点的$u(t)$之间的微分方程之间的关系及编辑条件为模型I

   

2. 由于存在未知量$\beta$, 推导出正问题的解或者解决正问题的算法A为

   A($\beta$) = u, 形式化的表达为
   $$
   u^{(out)} = u^{(out)}(x,t; \alpha, \beta)
   $$
   其中x,t为自变量. 即一旦给定$\beta$, 就能求出正问题解

3. 建立反问题模型

   确定待定量$\beta$的思想类似于“监督学习”, 用部分已知状态作为优化目标, 但其中所有变量都必须满足模型I. 例如用最小二乘定义泛函: 
   $$
   J(\beta) = \sum_{i=1}^{N}(u^{(out)}(x_i, t_i; \alpha, \beta) - u_i^{(in)})^2
   $$
   反问题的终极模型即模型II: 
   $$
   求\beta^* \in \phi, 在满足模型I时, 使得J(\beta^*)=\min_{\beta\in\phi} J(\beta)
   $$
   $\phi$ 表示未知参数向量$\beta$的参数空间

   

   > [!NOTE]
   >
   > 注意! 此处的数学方法需要理解, 以这种方式表述不会扣分

   

4. 确定模型II的求解方法(算法B): 一般为数值方法, 这部分包括: 

   - 求解正问题模型I
   - 求解模型II的数值方法
   - 二者交织的算法

   抽象自==炉温曲线==求解传热系数的算法: 

   Step0. 取初值$\beta^{(k)}$, 选择某种优化方法, 对优化方法A的循环进行步骤: 

   Step1. 计算正问题$u^{(out)}(x,t;\alpha, \beta^{(k)})$

   Step2. 计算误差$E$, 记为$E_k$

   Step3. 如果$E_k < E$, 则更新最优值

   Step4. 如果优化方法满足收敛条件, 则终止; 否则则根据优化方法A计算出下一步的$\beta^{(k+1)}$ 

   Step5. k = k+1, goto Step1, 直到在Step4结束. 

### 反问题和最优化问题的区别

反问题的优化过程

